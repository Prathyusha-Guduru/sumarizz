{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import io\n",
        "from PyPDF2 import PdfReader\n",
        "import time\n",
        "from urllib.parse import quote\n",
        "import os\n",
        "import csv\n",
        "import difflib\n",
        "import re\n",
        "import os\n",
        "import csv\n",
        "import PyPDF2\n",
        "from pathlib import Path\n",
        "import argparse\n",
        "import tqdm\n",
        "import fitz  # PyMuPDF - better PDF extraction\n",
        "from script import extract_text_from_pdf, clean_text"
      ],
      "metadata": {
        "id": "1x7QdJgZz_Yu"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngetu6ZcnPYs",
        "outputId": "651e0899-4067-4f65-a6c4-ba54be9eb787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 108 paper URLs.\n"
          ]
        }
      ],
      "source": [
        "base_url = \"https://www.aimodels.fyi\"\n",
        "papers_page = \"/papers?search=&selectedTimeRange=thisYear&page={}\"\n",
        "PDF_DIR='arxiv_pdfs'\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "paper_urls = []\n",
        "\n",
        "# Iterate through the first 5 pages (adjust as needed)\n",
        "for page_num in range(1,10):\n",
        "    url = base_url + papers_page.format(page_num)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all paper links\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        href = link['href']\n",
        "        #print(href)\n",
        "        if href.startswith('/papers/arxiv/'):\n",
        "            full_url = base_url + href\n",
        "            #print(full_url)\n",
        "            if full_url not in paper_urls:\n",
        "                paper_urls.append(full_url)\n",
        "        #print(paper_urls)\n",
        "\n",
        "print(f\"Found {len(paper_urls)} paper URLs.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_summary_and_pdf(paper_url):\n",
        "    response = requests.get(paper_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    head_div = soup.find('div', class_= 'css-b1ilzc')\n",
        "    heading = head_div.find('h1')\n",
        "    heading = heading.get_text(\" \", strip=True)\n",
        "\n",
        "    summary_div = soup.find('div', class_='css-79elbk')\n",
        "\n",
        "    if not summary_div:\n",
        "        return 'No summary found.', paper_url\n",
        "\n",
        "    # Replace all <h2> and <p> tags with plain text in a continuous format\n",
        "    parts = []\n",
        "    for element in summary_div.find_all(['h2', 'p', 'li']):\n",
        "        if element.name == 'h2':\n",
        "            text = element.get_text(\" \", strip=True)\n",
        "            text = '**'+text+'**'\n",
        "            parts.append(text)\n",
        "        else:\n",
        "          text = element.get_text(\" \", strip=True)\n",
        "          parts.append(text)\n",
        "\n",
        "    summary = ' '.join(parts)  # Join all parts with a space\n",
        "\n",
        "    return summary, heading, paper_url"
      ],
      "metadata": {
        "id": "eB9Uey69nw5y"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARXIV_API_URL = \"http://export.arxiv.org/api/query?search_query=ti:\\\"{}\\\"&max_results=1\"\n",
        "\n",
        "def find_arxiv_id_by_title(title, similarity_threshold=0.8):\n",
        "    query_url = ARXIV_API_URL.format(quote(title))\n",
        "    response = requests.get(query_url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to search arXiv for: {title}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        import xml.etree.ElementTree as ET\n",
        "        root = ET.fromstring(response.text)\n",
        "        entries = root.findall(\"{http://www.w3.org/2005/Atom}entry\")\n",
        "        best_match = None\n",
        "        best_score = 0\n",
        "\n",
        "        for entry in entries:\n",
        "            arxiv_title = entry.find(\"{http://www.w3.org/2005/Atom}title\").text.strip()\n",
        "            score = difflib.SequenceMatcher(None, title.strip().lower(), arxiv_title.lower()).ratio()\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_match = entry\n",
        "\n",
        "        if best_match and best_score >= similarity_threshold:\n",
        "            arxiv_id_url = best_match.find(\"{http://www.w3.org/2005/Atom}id\").text\n",
        "            arxiv_id = arxiv_id_url.split('/abs/')[-1]\n",
        "            print(f\"Fuzzy match found (score={best_score:.2f}): {arxiv_id}\")\n",
        "            return arxiv_id\n",
        "        else:\n",
        "            print(f\"No good match found for: {title} (best score: {best_score:.2f})\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing arXiv response for title '{title}': {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "RBJjBBSb49hi"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pdf(heading, arxiv_id):\n",
        "    pdf_url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
        "    response = requests.get(pdf_url)\n",
        "    if response.status_code == 200:\n",
        "      file_path = os.path.join(PDF_DIR, f\"{heading}.pdf\")\n",
        "      print(f\"Downloading {file_path}\")\n",
        "      with open(file_path, 'wb') as f:\n",
        "          f.write(response.content)\n",
        "      return file_path, io.BytesIO(response.content)\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "2cuxUBg55Q2E"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_pdf_pages(pdf_stream):\n",
        "    try:\n",
        "        reader = PdfReader(pdf_stream)\n",
        "        print(f\"Found {len(reader.pages)} pages\")\n",
        "        return len(reader.pages)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "EWHFP-Ov5R8X"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('papers_summary.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    fieldnames = ['link','heading','arxiv_id','file_path','page_count','pdf_text','summary']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for paper_url in paper_urls:\n",
        "        summary, heading, paper_url = extract_summary_and_pdf(paper_url)\n",
        "        print(f\"{heading}\")\n",
        "\n",
        "        arxiv_id = find_arxiv_id_by_title(heading)\n",
        "        file_path, pdf = download_pdf(heading, arxiv_id)\n",
        "\n",
        "        if pdf:\n",
        "            num_pages = count_pdf_pages(pdf)\n",
        "            print(f\"{num_pages} pages\")\n",
        "\n",
        "        cleaned_pdf_text = \"\"\n",
        "        if file_path and os.path.exists(file_path) and (num_pages<50):\n",
        "            print(f\"Extracting and cleaning PDF: {file_path}\")\n",
        "            raw_text = extract_text_from_pdf(file_path)\n",
        "            if raw_text:\n",
        "                cleaned_pdf_text = clean_text(raw_text)\n",
        "            else:\n",
        "                print(f\"Could not extract text from PDF: {file_path}\")\n",
        "\n",
        "        if arxiv_id is not None:\n",
        "            writer.writerow({\n",
        "                'link': paper_url,\n",
        "                'heading': heading,\n",
        "                'arxiv_id': arxiv_id,\n",
        "                'file_path': file_path,\n",
        "                'page_count':num_pages,\n",
        "                'pdf_text': cleaned_pdf_text,\n",
        "                'summary': summary\n",
        "            })\n",
        "            print(f\"Entry completed for {heading}\")\n",
        "            print(\"---------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbjZHZyhn72I",
        "outputId": "74af099d-cb55-414f-8ad9-a6070a8d1864"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model\n",
            "Fuzzy match found (score=1.00): 2408.07541v1\n",
            "Downloading arxiv_pdfs/DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model.pdf\n",
            "Found 11 pages\n",
            "11 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model.pdf\n",
            "Initial text length: 38777 characters\n",
            "Removing contributors to reduce text length (38777 characters)\n",
            "Final text length: 17149 characters\n",
            "Entry completed for DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model\n",
            "---------------------------------------------------------------------------------------\n",
            "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\n",
            "Fuzzy match found (score=0.99): 2501.12948v1\n",
            "Downloading arxiv_pdfs/DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.pdf\n",
            "Found 22 pages\n",
            "22 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.pdf\n",
            "Initial text length: 56719 characters\n",
            "Removing contributors to reduce text length (56719 characters)\n",
            "Removing abstract to reduce text length (43253 characters)\n",
            "Removing references to reduce text length (43253 characters)\n",
            "Removing appendix to reduce text length (32802 characters)\n",
            "Removing acknowledgments to reduce text length (32802 characters)\n",
            "Removing citations to reduce text length (32802 characters)\n",
            "Removing emails to reduce text length (32475 characters)\n",
            "Removing page_numbers to reduce text length (32475 characters)\n",
            "Still over 30k after removing sections, truncating (32445 characters)\n",
            "Final text length: 29996 characters\n",
            "Entry completed for DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\n",
            "---------------------------------------------------------------------------------------\n",
            "The Elements of Differentiable Programming\n",
            "Fuzzy match found (score=1.00): 2403.14606v2\n",
            "Downloading arxiv_pdfs/The Elements of Differentiable Programming.pdf\n",
            "Found 451 pages\n",
            "451 pages\n",
            "Entry completed for The Elements of Differentiable Programming\n",
            "---------------------------------------------------------------------------------------\n",
            "The Chemputer and Chemputation: A Universal Chemical Compound Synthesis Machine\n",
            "Fuzzy match found (score=0.99): 2408.09171v1\n",
            "Downloading arxiv_pdfs/The Chemputer and Chemputation: A Universal Chemical Compound Synthesis Machine.pdf\n",
            "Found 11 pages\n",
            "11 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/The Chemputer and Chemputation: A Universal Chemical Compound Synthesis Machine.pdf\n",
            "Initial text length: 19739 characters\n",
            "Text is already under 30k characters, keeping all content.\n",
            "Entry completed for The Chemputer and Chemputation: A Universal Chemical Compound Synthesis Machine\n",
            "---------------------------------------------------------------------------------------\n",
            "xLSTMTime : Long-term Time Series Forecasting With xLSTM\n",
            "No good match found for: xLSTMTime : Long-term Time Series Forecasting With xLSTM (best score: 0.00)\n",
            "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated\n",
            "No good match found for: Q-Sparse: All Large Language Models can be Fully Sparsely-Activated (best score: 0.00)\n",
            "Distilling System 2 into System 1\n",
            "Fuzzy match found (score=1.00): 2407.06023v3\n",
            "Downloading arxiv_pdfs/Distilling System 2 into System 1.pdf\n",
            "Found 16 pages\n",
            "16 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Distilling System 2 into System 1.pdf\n",
            "Initial text length: 61029 characters\n",
            "Removing contributors to reduce text length (61029 characters)\n",
            "Final text length: 27344 characters\n",
            "Entry completed for Distilling System 2 into System 1\n",
            "---------------------------------------------------------------------------------------\n",
            "Automated Design of Agentic Systems\n",
            "Fuzzy match found (score=1.00): 2408.08435v2\n",
            "Downloading arxiv_pdfs/Automated Design of Agentic Systems.pdf\n",
            "Found 34 pages\n",
            "34 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Automated Design of Agentic Systems.pdf\n",
            "Initial text length: 117328 characters\n",
            "Removing contributors to reduce text length (117328 characters)\n",
            "Cleaned text too short (651 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Automated Design of Agentic Systems\n",
            "---------------------------------------------------------------------------------------\n",
            "Learning to (Learn at Test Time): RNNs with Expressive Hidden States\n",
            "Fuzzy match found (score=1.00): 2407.04620v3\n",
            "Downloading arxiv_pdfs/Learning to (Learn at Test Time): RNNs with Expressive Hidden States.pdf\n",
            "Found 32 pages\n",
            "32 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Learning to (Learn at Test Time): RNNs with Expressive Hidden States.pdf\n",
            "Initial text length: 91175 characters\n",
            "Removing contributors to reduce text length (91175 characters)\n",
            "Cleaned text too short (448 chars), reverting to truncated original\n",
            "Final text length: 29997 characters\n",
            "Entry completed for Learning to (Learn at Test Time): RNNs with Expressive Hidden States\n",
            "---------------------------------------------------------------------------------------\n",
            "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge\n",
            "No good match found for: Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge (best score: 0.00)\n",
            "To Code, or Not To Code? Exploring Impact of Code in Pre-training\n",
            "No good match found for: To Code, or Not To Code? Exploring Impact of Code in Pre-training (best score: 0.00)\n",
            "LLM Pruning and Distillation in Practice: The Minitron Approach\n",
            "Fuzzy match found (score=1.00): 2408.11796v4\n",
            "Downloading arxiv_pdfs/LLM Pruning and Distillation in Practice: The Minitron Approach.pdf\n",
            "Found 11 pages\n",
            "11 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LLM Pruning and Distillation in Practice: The Minitron Approach.pdf\n",
            "Initial text length: 42600 characters\n",
            "Removing contributors to reduce text length (42600 characters)\n",
            "Cleaned text too short (14090 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for LLM Pruning and Distillation in Practice: The Minitron Approach\n",
            "---------------------------------------------------------------------------------------\n",
            "Differential Transformer\n",
            "Fuzzy match found (score=1.00): 2410.05258v2\n",
            "Downloading arxiv_pdfs/Differential Transformer.pdf\n",
            "Found 21 pages\n",
            "21 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Differential Transformer.pdf\n",
            "Initial text length: 63404 characters\n",
            "Removing contributors to reduce text length (63404 characters)\n",
            "Cleaned text too short (570 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Differential Transformer\n",
            "---------------------------------------------------------------------------------------\n",
            "Were RNNs All We Needed?\n",
            "Fuzzy match found (score=1.00): 2410.01201v3\n",
            "Downloading arxiv_pdfs/Were RNNs All We Needed?.pdf\n",
            "Found 27 pages\n",
            "27 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Were RNNs All We Needed?.pdf\n",
            "Initial text length: 72571 characters\n",
            "Removing contributors to reduce text length (72571 characters)\n",
            "Cleaned text too short (9389 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Were RNNs All We Needed?\n",
            "---------------------------------------------------------------------------------------\n",
            "The FFT Strikes Back: An Efficient Alternative to Self-Attention\n",
            "No good match found for: The FFT Strikes Back: An Efficient Alternative to Self-Attention (best score: 0.00)\n",
            "Surveilling the Masses with Wi-Fi-Based Positioning Systems\n",
            "No good match found for: Surveilling the Masses with Wi-Fi-Based Positioning Systems (best score: 0.00)\n",
            "WildGaussians: 3D Gaussian Splatting in the Wild\n",
            "Fuzzy match found (score=1.00): 2407.08447v2\n",
            "Downloading arxiv_pdfs/WildGaussians: 3D Gaussian Splatting in the Wild.pdf\n",
            "Found 16 pages\n",
            "16 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/WildGaussians: 3D Gaussian Splatting in the Wild.pdf\n",
            "Initial text length: 55768 characters\n",
            "Removing contributors to reduce text length (55768 characters)\n",
            "Cleaned text too short (1420 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for WildGaussians: 3D Gaussian Splatting in the Wild\n",
            "---------------------------------------------------------------------------------------\n",
            "ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities\n",
            "Fuzzy match found (score=0.99): 2408.04682v1\n",
            "Downloading arxiv_pdfs/ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities.pdf\n",
            "Found 21 pages\n",
            "21 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities.pdf\n",
            "Initial text length: 68647 characters\n",
            "Removing contributors to reduce text length (68647 characters)\n",
            "Cleaned text too short (6499 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities\n",
            "---------------------------------------------------------------------------------------\n",
            "Imagen 3\n",
            "Fuzzy match found (score=1.00): 2408.07009v3\n",
            "Downloading arxiv_pdfs/Imagen 3.pdf\n",
            "Found 35 pages\n",
            "35 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Imagen 3.pdf\n",
            "Initial text length: 83551 characters\n",
            "Removing contributors to reduce text length (83551 characters)\n",
            "Final text length: 22099 characters\n",
            "Entry completed for Imagen 3\n",
            "---------------------------------------------------------------------------------------\n",
            "Deep-TEMPEST: Using Deep Learning to Eavesdrop on HDMI from its Unintended Electromagnetic Emanations\n",
            "Fuzzy match found (score=0.99): 2407.09717v1\n",
            "Downloading arxiv_pdfs/Deep-TEMPEST: Using Deep Learning to Eavesdrop on HDMI from its Unintended Electromagnetic Emanations.pdf\n",
            "Found 10 pages\n",
            "10 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Deep-TEMPEST: Using Deep Learning to Eavesdrop on HDMI from its Unintended Electromagnetic Emanations.pdf\n",
            "Initial text length: 59528 characters\n",
            "Removing contributors to reduce text length (59528 characters)\n",
            "Cleaned text too short (8236 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Deep-TEMPEST: Using Deep Learning to Eavesdrop on HDMI from its Unintended Electromagnetic Emanations\n",
            "---------------------------------------------------------------------------------------\n",
            "TimeGPT-1\n",
            "Fuzzy match found (score=1.00): 2310.03589v3\n",
            "Downloading arxiv_pdfs/TimeGPT-1.pdf\n",
            "Found 12 pages\n",
            "12 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/TimeGPT-1.pdf\n",
            "Initial text length: 36332 characters\n",
            "Removing contributors to reduce text length (36332 characters)\n",
            "Cleaned text too short (46 chars), reverting to truncated original\n",
            "Final text length: 29996 characters\n",
            "Entry completed for TimeGPT-1\n",
            "---------------------------------------------------------------------------------------\n",
            "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\n",
            "Fuzzy match found (score=0.99): 2404.14219v4\n",
            "Downloading arxiv_pdfs/Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone.pdf\n",
            "Found 24 pages\n",
            "24 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone.pdf\n",
            "Initial text length: 56688 characters\n",
            "Removing contributors to reduce text length (56688 characters)\n",
            "Cleaned text too short (1835 chars), reverting to truncated original\n",
            "Final text length: 29997 characters\n",
            "Entry completed for Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\n",
            "---------------------------------------------------------------------------------------\n",
            "LIMO: Less is More for Reasoning\n",
            "Fuzzy match found (score=1.00): 2502.03387v1\n",
            "Downloading arxiv_pdfs/LIMO: Less is More for Reasoning.pdf\n",
            "Found 17 pages\n",
            "17 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LIMO: Less is More for Reasoning.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:PyPDF2._cmap:unknown widths : \n",
            "[0, [512, 0, 0, 250, 0, 408], 6, 9, 0, 10, [180, 333, 333, 500, 564, 250, 333, 250, 278], 19, 28, 500, 29, 30, 278, 31, [0, 564, 0, 444, 0, 722, 667, 667, 722, 611, 556, 722, 722, 333, 389, 722, 611, 889, 722, 722, 556, 722, 667, 556, 611, 722, 722, 944, 0, 719, 611, 333, 278, 333, 0, 500, 333, 444, 500, 444, 500, 444, 333, 500, 500, 278, 278, 500, 278, 778], 81, 84, 500, 85, [333, 389, 278, 500, 500, 722, 500, 500, 444, 480, 0, 480], 97, 199, 0, 200, [444], 201, 219, 0, 220, [444], 221, 285, 0, 286, [500], 287, 304, 0, 305, 306, 556, 307, [604, 821, 814, 0, 333], 312, 319, 0, 320, [333], 321, 336, 0, 337, [1000], 338, IndirectObject(548, 0, 135346077206736), 0, 343, 344, 444, 345, 391, 0, 392, [490]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial text length: 81943 characters\n",
            "Removing contributors to reduce text length (81943 characters)\n",
            "Final text length: 29894 characters\n",
            "Entry completed for LIMO: Less is More for Reasoning\n",
            "---------------------------------------------------------------------------------------\n",
            "LADDER: Self-Improving LLMs Through Recursive Problem Decomposition\n",
            "No good match found for: LADDER: Self-Improving LLMs Through Recursive Problem Decomposition (best score: 0.00)\n",
            "Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models\n",
            "No good match found for: Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models (best score: 0.00)\n",
            "Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse\n",
            "No good match found for: Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse (best score: 0.00)\n",
            "Aurora: A Foundation Model of the Atmosphere\n",
            "No good match found for: Aurora: A Foundation Model of the Atmosphere (best score: 0.00)\n",
            "Large Language Monkeys: Scaling Inference Compute with Repeated Sampling\n",
            "Fuzzy match found (score=1.00): 2407.21787v3\n",
            "Downloading arxiv_pdfs/Large Language Monkeys: Scaling Inference Compute with Repeated Sampling.pdf\n",
            "Found 27 pages\n",
            "27 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Large Language Monkeys: Scaling Inference Compute with Repeated Sampling.pdf\n",
            "Initial text length: 75621 characters\n",
            "Removing contributors to reduce text length (75621 characters)\n",
            "Cleaned text too short (2182 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Large Language Monkeys: Scaling Inference Compute with Repeated Sampling\n",
            "---------------------------------------------------------------------------------------\n",
            "Mixture of Nested Experts: Adaptive Processing of Visual Tokens\n",
            "Fuzzy match found (score=1.00): 2407.19985v2\n",
            "Downloading arxiv_pdfs/Mixture of Nested Experts: Adaptive Processing of Visual Tokens.pdf\n",
            "Found 14 pages\n",
            "14 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Mixture of Nested Experts: Adaptive Processing of Visual Tokens.pdf\n",
            "Initial text length: 44533 characters\n",
            "Removing contributors to reduce text length (44533 characters)\n",
            "Cleaned text too short (643 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Mixture of Nested Experts: Adaptive Processing of Visual Tokens\n",
            "---------------------------------------------------------------------------------------\n",
            "Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters\n",
            "No good match found for: Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters (best score: 0.00)\n",
            "JPEG-LM: LLMs as Image Generators with Canonical Codec Representations\n",
            "Fuzzy match found (score=1.00): 2408.08459v2\n",
            "Downloading arxiv_pdfs/JPEG-LM: LLMs as Image Generators with Canonical Codec Representations.pdf\n",
            "Found 17 pages\n",
            "17 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/JPEG-LM: LLMs as Image Generators with Canonical Codec Representations.pdf\n",
            "Initial text length: 51148 characters\n",
            "Removing contributors to reduce text length (51148 characters)\n",
            "Cleaned text too short (4938 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for JPEG-LM: LLMs as Image Generators with Canonical Codec Representations\n",
            "---------------------------------------------------------------------------------------\n",
            "Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping\n",
            "Fuzzy match found (score=0.99): 2402.14083v2\n",
            "Downloading arxiv_pdfs/Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping.pdf\n",
            "Found 21 pages\n",
            "21 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping.pdf\n",
            "Initial text length: 71808 characters\n",
            "Removing contributors to reduce text length (71808 characters)\n",
            "Cleaned text too short (4574 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping\n",
            "---------------------------------------------------------------------------------------\n",
            "Mixture of A Million Experts\n",
            "Fuzzy match found (score=1.00): 2407.04153v1\n",
            "Downloading arxiv_pdfs/Mixture of A Million Experts.pdf\n",
            "Found 12 pages\n",
            "12 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Mixture of A Million Experts.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:PyPDF2.generic._base:FloatObject (b'0.00-27839642') invalid; use 0.0 instead\n",
            "WARNING:PyPDF2.generic._base:FloatObject (b'0.00-27839642') invalid; use 0.0 instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial text length: 40321 characters\n",
            "Removing contributors to reduce text length (40321 characters)\n",
            "Cleaned text too short (14097 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Mixture of A Million Experts\n",
            "---------------------------------------------------------------------------------------\n",
            "StructuredRAG: JSON Response Formatting with Large Language Models\n",
            "Fuzzy match found (score=1.00): 2408.11061v1\n",
            "Downloading arxiv_pdfs/StructuredRAG: JSON Response Formatting with Large Language Models.pdf\n",
            "Found 10 pages\n",
            "10 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/StructuredRAG: JSON Response Formatting with Large Language Models.pdf\n",
            "Initial text length: 27853 characters\n",
            "Text is already under 30k characters, keeping all content.\n",
            "Entry completed for StructuredRAG: JSON Response Formatting with Large Language Models\n",
            "---------------------------------------------------------------------------------------\n",
            "Better & Faster Large Language Models via Multi-token Prediction\n",
            "No good match found for: Better & Faster Large Language Models via Multi-token Prediction (best score: 0.00)\n",
            "Chameleon: Mixed-Modal Early-Fusion Foundation Models\n",
            "No good match found for: Chameleon: Mixed-Modal Early-Fusion Foundation Models (best score: 0.00)\n",
            "{sigma}-GPTs: A New Approach to Autoregressive Models\n",
            "No good match found for: {sigma}-GPTs: A New Approach to Autoregressive Models (best score: 0.00)\n",
            "PaliGemma: A versatile 3B VLM for transfer\n",
            "Fuzzy match found (score=1.00): 2407.07726v2\n",
            "Downloading arxiv_pdfs/PaliGemma: A versatile 3B VLM for transfer.pdf\n",
            "Found 59 pages\n",
            "59 pages\n",
            "Entry completed for PaliGemma: A versatile 3B VLM for transfer\n",
            "---------------------------------------------------------------------------------------\n",
            "An Abundance of Katherines: The Game Theory of Baby Naming\n",
            "Fuzzy match found (score=1.00): 2404.00732v3\n",
            "Downloading arxiv_pdfs/An Abundance of Katherines: The Game Theory of Baby Naming.pdf\n",
            "Found 10 pages\n",
            "10 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/An Abundance of Katherines: The Game Theory of Baby Naming.pdf\n",
            "Initial text length: 20154 characters\n",
            "Text is already under 30k characters, keeping all content.\n",
            "Entry completed for An Abundance of Katherines: The Game Theory of Baby Naming\n",
            "---------------------------------------------------------------------------------------\n",
            "More Agents Is All You Need\n",
            "Fuzzy match found (score=1.00): 2402.05120v2\n",
            "Downloading arxiv_pdfs/More Agents Is All You Need.pdf\n",
            "Found 18 pages\n",
            "18 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/More Agents Is All You Need.pdf\n",
            "Initial text length: 55346 characters\n",
            "Removing contributors to reduce text length (55346 characters)\n",
            "Cleaned text too short (1924 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for More Agents Is All You Need\n",
            "---------------------------------------------------------------------------------------\n",
            "Training Large Language Models to Reason in a Continuous Latent Space\n",
            "Fuzzy match found (score=1.00): 2412.06769v2\n",
            "Downloading arxiv_pdfs/Training Large Language Models to Reason in a Continuous Latent Space.pdf\n",
            "Found 17 pages\n",
            "17 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Training Large Language Models to Reason in a Continuous Latent Space.pdf\n",
            "Initial text length: 56602 characters\n",
            "Removing contributors to reduce text length (56602 characters)\n",
            "Cleaned text too short (1787 chars), reverting to truncated original\n",
            "Final text length: 29997 characters\n",
            "Entry completed for Training Large Language Models to Reason in a Continuous Latent Space\n",
            "---------------------------------------------------------------------------------------\n",
            "LLMs Will Always Hallucinate, and We Need to Live With This\n",
            "Fuzzy match found (score=1.00): 2409.05746v1\n",
            "Downloading arxiv_pdfs/LLMs Will Always Hallucinate, and We Need to Live With This.pdf\n",
            "Found 31 pages\n",
            "31 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LLMs Will Always Hallucinate, and We Need to Live With This.pdf\n",
            "Initial text length: 78370 characters\n",
            "Removing contributors to reduce text length (78370 characters)\n",
            "Final text length: 20336 characters\n",
            "Entry completed for LLMs Will Always Hallucinate, and We Need to Live With This\n",
            "---------------------------------------------------------------------------------------\n",
            "Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs\n",
            "No good match found for: Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs (best score: 0.00)\n",
            "Planting Undetectable Backdoors in Machine Learning Models\n",
            "Fuzzy match found (score=1.00): 2204.06974v2\n",
            "Downloading arxiv_pdfs/Planting Undetectable Backdoors in Machine Learning Models.pdf\n",
            "Found 53 pages\n",
            "53 pages\n",
            "Entry completed for Planting Undetectable Backdoors in Machine Learning Models\n",
            "---------------------------------------------------------------------------------------\n",
            "Accuracy is Not All You Need\n",
            "Fuzzy match found (score=1.00): 2407.09141v1\n",
            "Downloading arxiv_pdfs/Accuracy is Not All You Need.pdf\n",
            "Found 26 pages\n",
            "26 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Accuracy is Not All You Need.pdf\n",
            "Initial text length: 97871 characters\n",
            "Removing contributors to reduce text length (97871 characters)\n",
            "Cleaned text too short (9940 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Accuracy is Not All You Need\n",
            "---------------------------------------------------------------------------------------\n",
            "Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models\n",
            "Fuzzy match found (score=0.99): 2408.08210v1\n",
            "Downloading arxiv_pdfs/Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models.pdf\n",
            "Found 21 pages\n",
            "21 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models.pdf\n",
            "Initial text length: 63836 characters\n",
            "Removing contributors to reduce text length (63836 characters)\n",
            "Cleaned text too short (120 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models\n",
            "---------------------------------------------------------------------------------------\n",
            "Hardware Acceleration of LLMs: A comprehensive survey and comparison\n",
            "Fuzzy match found (score=1.00): 2409.03384v1\n",
            "Downloading arxiv_pdfs/Hardware Acceleration of LLMs: A comprehensive survey and comparison.pdf\n",
            "Found 15 pages\n",
            "15 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Hardware Acceleration of LLMs: A comprehensive survey and comparison.pdf\n",
            "Initial text length: 63974 characters\n",
            "Removing contributors to reduce text length (63974 characters)\n",
            "Cleaned text too short (405 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Hardware Acceleration of LLMs: A comprehensive survey and comparison\n",
            "---------------------------------------------------------------------------------------\n",
            "Transformer Layers as Painters\n",
            "Fuzzy match found (score=1.00): 2407.09298v4\n",
            "Downloading arxiv_pdfs/Transformer Layers as Painters.pdf\n",
            "Found 13 pages\n",
            "13 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Transformer Layers as Painters.pdf\n",
            "Initial text length: 45645 characters\n",
            "Removing contributors to reduce text length (45645 characters)\n",
            "Cleaned text too short (53 chars), reverting to truncated original\n",
            "Final text length: 29997 characters\n",
            "Entry completed for Transformer Layers as Painters\n",
            "---------------------------------------------------------------------------------------\n",
            "Bytes Are All You Need: Transformers Operating Directly On File Bytes\n",
            "Fuzzy match found (score=1.00): 2306.00238v2\n",
            "Downloading arxiv_pdfs/Bytes Are All You Need: Transformers Operating Directly On File Bytes.pdf\n",
            "Found 17 pages\n",
            "17 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Bytes Are All You Need: Transformers Operating Directly On File Bytes.pdf\n",
            "Initial text length: 59810 characters\n",
            "Removing contributors to reduce text length (59810 characters)\n",
            "Cleaned text too short (2668 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Bytes Are All You Need: Transformers Operating Directly On File Bytes\n",
            "---------------------------------------------------------------------------------------\n",
            "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems\n",
            "Fuzzy match found (score=0.99): 2402.12875v4\n",
            "Downloading arxiv_pdfs/Chain of Thought Empowers Transformers to Solve Inherently Serial Problems.pdf\n",
            "Found 38 pages\n",
            "38 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Chain of Thought Empowers Transformers to Solve Inherently Serial Problems.pdf\n",
            "Initial text length: 102231 characters\n",
            "Removing contributors to reduce text length (102231 characters)\n",
            "Cleaned text too short (5863 chars), reverting to truncated original\n",
            "Final text length: 29993 characters\n",
            "Entry completed for Chain of Thought Empowers Transformers to Solve Inherently Serial Problems\n",
            "---------------------------------------------------------------------------------------\n",
            "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models\n",
            "Fuzzy match found (score=0.99): 2410.05229v1\n",
            "Downloading arxiv_pdfs/GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models.pdf\n",
            "Found 22 pages\n",
            "22 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models.pdf\n",
            "Initial text length: 67413 characters\n",
            "Removing contributors to reduce text length (67413 characters)\n",
            "Cleaned text too short (4033 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models\n",
            "---------------------------------------------------------------------------------------\n",
            "TPI-LLM: Serving 70B-scale LLMs Efficiently on Low-resource Edge Devices\n",
            "No good match found for: TPI-LLM: Serving 70B-scale LLMs Efficiently on Low-resource Edge Devices (best score: 0.00)\n",
            "Bluesky and the AT Protocol: Usable Decentralized Social Media\n",
            "Fuzzy match found (score=1.00): 2402.03239v2\n",
            "Downloading arxiv_pdfs/Bluesky and the AT Protocol: Usable Decentralized Social Media.pdf\n",
            "Found 9 pages\n",
            "9 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Bluesky and the AT Protocol: Usable Decentralized Social Media.pdf\n",
            "Initial text length: 55884 characters\n",
            "Removing contributors to reduce text length (55884 characters)\n",
            "Final text length: 25887 characters\n",
            "Entry completed for Bluesky and the AT Protocol: Usable Decentralized Social Media\n",
            "---------------------------------------------------------------------------------------\n",
            "Collaborative Text Editing with Eg-walker: Better, Faster, Smaller\n",
            "Fuzzy match found (score=1.00): 2409.14252v1\n",
            "Downloading arxiv_pdfs/Collaborative Text Editing with Eg-walker: Better, Faster, Smaller.pdf\n",
            "Found 25 pages\n",
            "25 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Collaborative Text Editing with Eg-walker: Better, Faster, Smaller.pdf\n",
            "Initial text length: 129319 characters\n",
            "Removing contributors to reduce text length (129319 characters)\n",
            "Cleaned text too short (931 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Collaborative Text Editing with Eg-walker: Better, Faster, Smaller\n",
            "---------------------------------------------------------------------------------------\n",
            "Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization\n",
            "Fuzzy match found (score=0.99): 2405.15071v3\n",
            "Downloading arxiv_pdfs/Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization.pdf\n",
            "Found 22 pages\n",
            "22 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization.pdf\n",
            "Initial text length: 71115 characters\n",
            "Removing contributors to reduce text length (71115 characters)\n",
            "Cleaned text too short (185 chars), reverting to truncated original\n",
            "Final text length: 29997 characters\n",
            "Entry completed for Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization\n",
            "---------------------------------------------------------------------------------------\n",
            "LLMs cannot find reasoning errors, but can correct them given the error location\n",
            "Fuzzy match found (score=0.99): 2311.08516v3\n",
            "Downloading arxiv_pdfs/LLMs cannot find reasoning errors, but can correct them given the error location.pdf\n",
            "Found 15 pages\n",
            "15 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LLMs cannot find reasoning errors, but can correct them given the error location.pdf\n",
            "Initial text length: 51829 characters\n",
            "Removing contributors to reduce text length (51829 characters)\n",
            "Cleaned text too short (981 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for LLMs cannot find reasoning errors, but can correct them given the error location\n",
            "---------------------------------------------------------------------------------------\n",
            "From pixels to planning: scale-free active inference\n",
            "No good match found for: From pixels to planning: scale-free active inference (best score: 0.00)\n",
            "Thermodynamic Linear Algebra\n",
            "Fuzzy match found (score=1.00): 2308.05660v2\n",
            "Downloading arxiv_pdfs/Thermodynamic Linear Algebra.pdf\n",
            "Found 37 pages\n",
            "37 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Thermodynamic Linear Algebra.pdf\n",
            "Initial text length: 94100 characters\n",
            "Removing contributors to reduce text length (94100 characters)\n",
            "Cleaned text too short (942 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Thermodynamic Linear Algebra\n",
            "---------------------------------------------------------------------------------------\n",
            "You Need to Pay Better Attention: Rethinking the Mathematics of Attention Mechanism\n",
            "No good match found for: You Need to Pay Better Attention: Rethinking the Mathematics of Attention Mechanism (best score: 0.00)\n",
            "Training Language Models to Self-Correct via Reinforcement Learning\n",
            "No good match found for: Training Language Models to Self-Correct via Reinforcement Learning (best score: 0.00)\n",
            "Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though\n",
            "No good match found for: Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though (best score: 0.00)\n",
            "TopoNets: High Performing Vision and Language Models with Brain-Like Topography\n",
            "No good match found for: TopoNets: High Performing Vision and Language Models with Brain-Like Topography (best score: 0.00)\n",
            "Neural Network Parameter Diffusion\n",
            "No good match found for: Neural Network Parameter Diffusion (best score: 0.00)\n",
            "Improving Retrieval Augmented Language Model with Self-Reasoning\n",
            "No good match found for: Improving Retrieval Augmented Language Model with Self-Reasoning (best score: 0.00)\n",
            "Tutorial on Diffusion Models for Imaging and Vision\n",
            "Fuzzy match found (score=1.00): 2403.18103v3\n",
            "Downloading arxiv_pdfs/Tutorial on Diffusion Models for Imaging and Vision.pdf\n",
            "Found 90 pages\n",
            "90 pages\n",
            "Entry completed for Tutorial on Diffusion Models for Imaging and Vision\n",
            "---------------------------------------------------------------------------------------\n",
            "Is artificial consciousness achievable? Lessons from the human brain\n",
            "Fuzzy match found (score=1.00): 2405.04540v2\n",
            "Downloading arxiv_pdfs/Is artificial consciousness achievable? Lessons from the human brain.pdf\n",
            "Found 41 pages\n",
            "41 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Is artificial consciousness achievable? Lessons from the human brain.pdf\n",
            "Initial text length: 122013 characters\n",
            "Removing contributors to reduce text length (122013 characters)\n",
            "Removing abstract to reduce text length (36971 characters)\n",
            "Removing references to reduce text length (36971 characters)\n",
            "Cleaned text too short (306 chars), reverting to truncated original\n",
            "Final text length: 29717 characters\n",
            "Entry completed for Is artificial consciousness achievable? Lessons from the human brain\n",
            "---------------------------------------------------------------------------------------\n",
            "Refusal in Language Models Is Mediated by a Single Direction\n",
            "Fuzzy match found (score=1.00): 2406.11717v3\n",
            "Downloading arxiv_pdfs/Refusal in Language Models Is Mediated by a Single Direction.pdf\n",
            "Found 40 pages\n",
            "40 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Refusal in Language Models Is Mediated by a Single Direction.pdf\n",
            "Initial text length: 119424 characters\n",
            "Removing contributors to reduce text length (119424 characters)\n",
            "Cleaned text too short (2151 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Refusal in Language Models Is Mediated by a Single Direction\n",
            "---------------------------------------------------------------------------------------\n",
            "Transformers Can Do Arithmetic with the Right Embeddings\n",
            "Fuzzy match found (score=1.00): 2405.17399v2\n",
            "Downloading arxiv_pdfs/Transformers Can Do Arithmetic with the Right Embeddings.pdf\n",
            "Found 30 pages\n",
            "30 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Transformers Can Do Arithmetic with the Right Embeddings.pdf\n",
            "Initial text length: 91052 characters\n",
            "Removing contributors to reduce text length (91052 characters)\n",
            "Cleaned text too short (480 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Transformers Can Do Arithmetic with the Right Embeddings\n",
            "---------------------------------------------------------------------------------------\n",
            "Reasoning in Large Language Models: A Geometric Perspective\n",
            "Fuzzy match found (score=1.00): 2407.02678v1\n",
            "Downloading arxiv_pdfs/Reasoning in Large Language Models: A Geometric Perspective.pdf\n",
            "Found 12 pages\n",
            "12 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Reasoning in Large Language Models: A Geometric Perspective.pdf\n",
            "Initial text length: 39325 characters\n",
            "Removing contributors to reduce text length (39325 characters)\n",
            "Final text length: 20992 characters\n",
            "Entry completed for Reasoning in Large Language Models: A Geometric Perspective\n",
            "---------------------------------------------------------------------------------------\n",
            "Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach\n",
            "No good match found for: Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach (best score: 0.00)\n",
            "Chronos: Learning the Language of Time Series\n",
            "Fuzzy match found (score=1.00): 2403.07815v3\n",
            "Downloading arxiv_pdfs/Chronos: Learning the Language of Time Series.pdf\n",
            "Found 43 pages\n",
            "43 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Chronos: Learning the Language of Time Series.pdf\n",
            "Initial text length: 341793 characters\n",
            "Removing contributors to reduce text length (341793 characters)\n",
            "Cleaned text too short (1976 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Chronos: Learning the Language of Time Series\n",
            "---------------------------------------------------------------------------------------\n",
            "Scalable MatMul-free Language Modeling\n",
            "No good match found for: Scalable MatMul-free Language Modeling (best score: 0.00)\n",
            "Yi: Open Foundation Models by 01.AI\n",
            "Fuzzy match found (score=1.00): 2403.04652v3\n",
            "Downloading arxiv_pdfs/Yi: Open Foundation Models by 01.AI.pdf\n",
            "Found 26 pages\n",
            "26 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Yi: Open Foundation Models by 01.AI.pdf\n",
            "Initial text length: 87316 characters\n",
            "Removing contributors to reduce text length (87316 characters)\n",
            "Final text length: 26961 characters\n",
            "Entry completed for Yi: Open Foundation Models by 01.AI\n",
            "---------------------------------------------------------------------------------------\n",
            "Self-Retrieval: End-to-End Information Retrieval with One Large Language Model\n",
            "No good match found for: Self-Retrieval: End-to-End Information Retrieval with One Large Language Model (best score: 0.00)\n",
            "Thermodynamic Natural Gradient Descent\n",
            "Fuzzy match found (score=1.00): 2405.13817v1\n",
            "Downloading arxiv_pdfs/Thermodynamic Natural Gradient Descent.pdf\n",
            "Found 17 pages\n",
            "17 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Thermodynamic Natural Gradient Descent.pdf\n",
            "Initial text length: 52855 characters\n",
            "Removing contributors to reduce text length (52855 characters)\n",
            "Cleaned text too short (586 chars), reverting to truncated original\n",
            "Final text length: 29997 characters\n",
            "Entry completed for Thermodynamic Natural Gradient Descent\n",
            "---------------------------------------------------------------------------------------\n",
            "Inference-Time Scaling for Generalist Reward Modeling\n",
            "No good match found for: Inference-Time Scaling for Generalist Reward Modeling (best score: 0.00)\n",
            "LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control\n",
            "Fuzzy match found (score=0.99): 2407.03168v2\n",
            "Downloading arxiv_pdfs/LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control.pdf\n",
            "Found 16 pages\n",
            "16 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control.pdf\n",
            "Initial text length: 134513 characters\n",
            "Removing contributors to reduce text length (134513 characters)\n",
            "Cleaned text too short (842 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control\n",
            "---------------------------------------------------------------------------------------\n",
            "SpreadsheetLLM: Encoding Spreadsheets for Large Language Models\n",
            "Fuzzy match found (score=1.00): 2407.09025v2\n",
            "Downloading arxiv_pdfs/SpreadsheetLLM: Encoding Spreadsheets for Large Language Models.pdf\n",
            "Found 21 pages\n",
            "21 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/SpreadsheetLLM: Encoding Spreadsheets for Large Language Models.pdf\n",
            "Initial text length: 72063 characters\n",
            "Removing contributors to reduce text length (72063 characters)\n",
            "Cleaned text too short (3581 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for SpreadsheetLLM: Encoding Spreadsheets for Large Language Models\n",
            "---------------------------------------------------------------------------------------\n",
            "OpenDevin: An Open Platform for AI Software Developers as Generalist Agents\n",
            "No good match found for: OpenDevin: An Open Platform for AI Software Developers as Generalist Agents (best score: 0.00)\n",
            "Amortized Planning with Large-Scale Transformers: A Case Study on Chess\n",
            "No good match found for: Amortized Planning with Large-Scale Transformers: A Case Study on Chess (best score: 0.00)\n",
            "An All-Optical General-Purpose CPU and Optical Computer Architecture\n",
            "No good match found for: An All-Optical General-Purpose CPU and Optical Computer Architecture (best score: 0.00)\n",
            "xLSTM: Extended Long Short-Term Memory\n",
            "No good match found for: xLSTM: Extended Long Short-Term Memory (best score: 0.00)\n",
            "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models\n",
            "Fuzzy match found (score=1.00): 2502.01142v1\n",
            "Downloading arxiv_pdfs/DeepRAG: Thinking to Retrieval Step by Step for Large Language Models.pdf\n",
            "Found 12 pages\n",
            "12 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/DeepRAG: Thinking to Retrieval Step by Step for Large Language Models.pdf\n",
            "Initial text length: 51049 characters\n",
            "Removing contributors to reduce text length (51049 characters)\n",
            "Final text length: 16878 characters\n",
            "Entry completed for DeepRAG: Thinking to Retrieval Step by Step for Large Language Models\n",
            "---------------------------------------------------------------------------------------\n",
            "Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold\n",
            "No good match found for: Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold (best score: 0.00)\n",
            "AI and the Problem of Knowledge Collapse\n",
            "Fuzzy match found (score=1.00): 2404.03502v2\n",
            "Downloading arxiv_pdfs/AI and the Problem of Knowledge Collapse.pdf\n",
            "Found 38 pages\n",
            "38 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/AI and the Problem of Knowledge Collapse.pdf\n",
            "Initial text length: 93887 characters\n",
            "Removing contributors to reduce text length (93887 characters)\n",
            "Cleaned text too short (0 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for AI and the Problem of Knowledge Collapse\n",
            "---------------------------------------------------------------------------------------\n",
            "Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions\n",
            "Fuzzy match found (score=0.99): 2407.20243v1\n",
            "Downloading arxiv_pdfs/Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions.pdf\n",
            "Found 19 pages\n",
            "19 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions.pdf\n",
            "Initial text length: 58802 characters\n",
            "Removing contributors to reduce text length (58802 characters)\n",
            "Cleaned text too short (1175 chars), reverting to truncated original\n",
            "Final text length: 29995 characters\n",
            "Entry completed for Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions\n",
            "---------------------------------------------------------------------------------------\n",
            "No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance\n",
            "No good match found for: No Zero-Shot Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance (best score: 0.00)\n",
            "LoRA+: Efficient Low Rank Adaptation of Large Models\n",
            "Fuzzy match found (score=1.00): 2402.12354v2\n",
            "Downloading arxiv_pdfs/LoRA+: Efficient Low Rank Adaptation of Large Models.pdf\n",
            "Found 24 pages\n",
            "24 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LoRA+: Efficient Low Rank Adaptation of Large Models.pdf\n",
            "Initial text length: 77103 characters\n",
            "Removing contributors to reduce text length (77103 characters)\n",
            "Cleaned text too short (12800 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for LoRA+: Efficient Low Rank Adaptation of Large Models\n",
            "---------------------------------------------------------------------------------------\n",
            "Magicoder: Empowering Code Generation with OSS-Instruct\n",
            "No good match found for: Magicoder: Empowering Code Generation with OSS-Instruct (best score: 0.00)\n",
            "Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models\n",
            "No good match found for: Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models (best score: 0.00)\n",
            "Can a Transformer Represent a Kalman Filter?\n",
            "Fuzzy match found (score=1.00): 2312.06937v3\n",
            "Downloading arxiv_pdfs/Can a Transformer Represent a Kalman Filter?.pdf\n",
            "Found 9 pages\n",
            "9 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Can a Transformer Represent a Kalman Filter?.pdf\n",
            "Initial text length: 26154 characters\n",
            "Text is already under 30k characters, keeping all content.\n",
            "Entry completed for Can a Transformer Represent a Kalman Filter?\n",
            "---------------------------------------------------------------------------------------\n",
            "MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training\n",
            "No good match found for: MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training (best score: 0.00)\n",
            "LLaVA-o1: Let Vision Language Models Reason Step-by-Step\n",
            "No good match found for: LLaVA-o1: Let Vision Language Models Reason Step-by-Step (best score: 0.00)\n",
            "LoRA Learns Less and Forgets Less\n",
            "Fuzzy match found (score=1.00): 2405.09673v2\n",
            "Downloading arxiv_pdfs/LoRA Learns Less and Forgets Less.pdf\n",
            "Found 39 pages\n",
            "39 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LoRA Learns Less and Forgets Less.pdf\n",
            "Initial text length: 97376 characters\n",
            "Removing contributors to reduce text length (97376 characters)\n",
            "Cleaned text too short (255 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for LoRA Learns Less and Forgets Less\n",
            "---------------------------------------------------------------------------------------\n",
            "LLMs Can Teach Themselves to Better Predict the Future\n",
            "Fuzzy match found (score=1.00): 2502.05253v1\n",
            "Downloading arxiv_pdfs/LLMs Can Teach Themselves to Better Predict the Future.pdf\n",
            "Found 10 pages\n",
            "10 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/LLMs Can Teach Themselves to Better Predict the Future.pdf\n",
            "Initial text length: 27280 characters\n",
            "Text is already under 30k characters, keeping all content.\n",
            "Entry completed for LLMs Can Teach Themselves to Better Predict the Future\n",
            "---------------------------------------------------------------------------------------\n",
            "TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters\n",
            "Fuzzy match found (score=0.99): 2410.23168v2\n",
            "Downloading arxiv_pdfs/TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters.pdf\n",
            "Found 18 pages\n",
            "18 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters.pdf\n",
            "Initial text length: 65032 characters\n",
            "Removing contributors to reduce text length (65032 characters)\n",
            "Cleaned text too short (8152 chars), reverting to truncated original\n",
            "Final text length: 29969 characters\n",
            "Entry completed for TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters\n",
            "---------------------------------------------------------------------------------------\n",
            "Expect the Unexpected: FailSafe Long Context QA for Finance\n",
            "Fuzzy match found (score=1.00): 2502.06329v1\n",
            "Downloading arxiv_pdfs/Expect the Unexpected: FailSafe Long Context QA for Finance.pdf\n",
            "Found 18 pages\n",
            "18 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Expect the Unexpected: FailSafe Long Context QA for Finance.pdf\n",
            "Initial text length: 68779 characters\n",
            "Removing contributors to reduce text length (68779 characters)\n",
            "Cleaned text too short (3672 chars), reverting to truncated original\n",
            "Final text length: 29972 characters\n",
            "Entry completed for Expect the Unexpected: FailSafe Long Context QA for Finance\n",
            "---------------------------------------------------------------------------------------\n",
            "Efficient Reasoning with Hidden Thinking\n",
            "Fuzzy match found (score=1.00): 2501.19201v1\n",
            "Downloading arxiv_pdfs/Efficient Reasoning with Hidden Thinking.pdf\n",
            "Found 14 pages\n",
            "14 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Efficient Reasoning with Hidden Thinking.pdf\n",
            "Initial text length: 53353 characters\n",
            "Removing contributors to reduce text length (53353 characters)\n",
            "Final text length: 26924 characters\n",
            "Entry completed for Efficient Reasoning with Hidden Thinking\n",
            "---------------------------------------------------------------------------------------\n",
            "Poisoning Web-Scale Training Datasets is Practical\n",
            "No good match found for: Poisoning Web-Scale Training Datasets is Practical (best score: 0.00)\n",
            "The Curse of Recursion: Training on Generated Data Makes Models Forget\n",
            "Fuzzy match found (score=1.00): 2305.17493v3\n",
            "Downloading arxiv_pdfs/The Curse of Recursion: Training on Generated Data Makes Models Forget.pdf\n",
            "Found 18 pages\n",
            "18 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/The Curse of Recursion: Training on Generated Data Makes Models Forget.pdf\n",
            "Initial text length: 61466 characters\n",
            "Removing contributors to reduce text length (61466 characters)\n",
            "Cleaned text too short (2020 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for The Curse of Recursion: Training on Generated Data Makes Models Forget\n",
            "---------------------------------------------------------------------------------------\n",
            "Training Language Models to Generate Text with Citations via Fine-grained Rewards\n",
            "No good match found for: Training Language Models to Generate Text with Citations via Fine-grained Rewards (best score: 0.00)\n",
            "OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework\n",
            "No good match found for: OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework (best score: 0.00)\n",
            "Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length\n",
            "Fuzzy match found (score=0.99): 2404.08801v2\n",
            "Downloading arxiv_pdfs/Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length.pdf\n",
            "Found 18 pages\n",
            "18 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length.pdf\n",
            "Initial text length: 119363 characters\n",
            "Removing contributors to reduce text length (119363 characters)\n",
            "Cleaned text too short (7896 chars), reverting to truncated original\n",
            "Final text length: 29381 characters\n",
            "Entry completed for Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length\n",
            "---------------------------------------------------------------------------------------\n",
            "Delving into ChatGPT usage in academic writing through excess vocabulary\n",
            "Fuzzy match found (score=1.00): 2406.07016v4\n",
            "Downloading arxiv_pdfs/Delving into ChatGPT usage in academic writing through excess vocabulary.pdf\n",
            "Found 13 pages\n",
            "13 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Delving into ChatGPT usage in academic writing through excess vocabulary.pdf\n",
            "Initial text length: 47019 characters\n",
            "Removing contributors to reduce text length (47019 characters)\n",
            "Cleaned text too short (5945 chars), reverting to truncated original\n",
            "Final text length: 29656 characters\n",
            "Entry completed for Delving into ChatGPT usage in academic writing through excess vocabulary\n",
            "---------------------------------------------------------------------------------------\n",
            "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text\n",
            "No good match found for: Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text (best score: 0.00)\n",
            "Evaluating the World Model Implicit in a Generative Model\n",
            "Fuzzy match found (score=1.00): 2406.03689v3\n",
            "Downloading arxiv_pdfs/Evaluating the World Model Implicit in a Generative Model.pdf\n",
            "Found 29 pages\n",
            "29 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Evaluating the World Model Implicit in a Generative Model.pdf\n",
            "Initial text length: 79114 characters\n",
            "Removing contributors to reduce text length (79114 characters)\n",
            "Cleaned text too short (8454 chars), reverting to truncated original\n",
            "Final text length: 29998 characters\n",
            "Entry completed for Evaluating the World Model Implicit in a Generative Model\n",
            "---------------------------------------------------------------------------------------\n",
            "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models\n",
            "Fuzzy match found (score=0.99): 2503.09573v2\n",
            "Downloading arxiv_pdfs/Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models.pdf\n",
            "Found 28 pages\n",
            "28 pages\n",
            "Extracting and cleaning PDF: arxiv_pdfs/Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models.pdf\n",
            "Initial text length: 97698 characters\n",
            "Removing contributors to reduce text length (97698 characters)\n",
            "Final text length: 22518 characters\n",
            "Entry completed for Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models\n",
            "---------------------------------------------------------------------------------------\n",
            "The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities\n",
            "No good match found for: The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities (best score: 0.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('arxiv_pdfs', 'zip', 'arxiv_pdfs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sr7smeBII4_q",
        "outputId": "f87cdb31-b369-49f6-bb53-d4b48addfb22"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/arxiv_pdfs.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    }
  ]
}